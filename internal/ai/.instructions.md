# Copilot Instructions for internal/ai (nixai Project)

## Purpose
- This package implements all AI/LLM provider logic for the nixai project.
- It provides a unified interface for querying and generating responses from multiple AI providers (Ollama, Gemini, OpenAI, etc.).
- It is responsible for prompt formatting, provider selection, and privacy-aware inference.

## Coding Guidelines
- Use Go idioms and keep code modular and well-documented.
- All providers must implement both `Query` and `GenerateResponse` methods.
- Default to Ollama with the "llama3" model if no provider is configured.
- Format prompts consistently across all providers.
- Never store API keys in config files; always use environment variables.
- Validate and sanitize all input to providers.
- Handle provider errors gracefully and return actionable error messages.
- Prefer local inference (Ollama) for privacy, but support cloud LLMs as fallback.
- Add or update tests for all new features and bugfixes.

## Features to Support
- Unified interface for querying LLMs (see `Provider` interface).
- Support for multiple providers: Ollama, Gemini, OpenAI (add more as needed).
- Allow user to select/configure provider and model via config/environment.
- Consistent prompt formatting and Markdown output.
- Graceful fallback if a provider is unavailable.
- Logging of provider selection and errors using `pkg/logger`.
- Testability: all providers and logic must be covered by unit tests.

## Best Practices
- Keep provider logic isolated in separate files (e.g., `ollama.go`, `openai.go`).
- Use context and error handling idiomatically.
- Use interfaces for extensibility and testability.
- Document all exported types and methods.
- Use `pkg/logger` for logging, respecting log level from config.
- Add examples and usage notes in code comments where helpful.

## Testing
- All providers must have corresponding test files (e.g., `ollama_test.go`).
- Mock external API calls in tests.
- Test both success and error/failure scenarios.

## Integration Points
- Used by CLI commands in `internal/cli` for all AI-powered features.
- Reads configuration from `internal/config`.
- Logs to `pkg/logger`.

---
> These instructions are for Copilot and contributors. Follow them to ensure consistency, maintainability, and feature completeness for the nixai AI implementation.
